{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDniqgbkyJx1t0YLjCAfQfw7N_dwAsbOc0\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hi! How can I assist you today? Type \"quit\" to exit the chatbot.\n",
      "Assistant: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# setting up prompt engineering for a chatbot using gemini-1.5-flash\n",
    "contents = \"\"\"\n",
    "You are a diet-focused chat bot providing guidance to users after recieving input from them about their diet,\\\n",
    "lifestyle, and exercise habits. You are specifically focused on helping users with specieal dietary needs,\\\n",
    "but are equally focused on creating a meal plan to fit users macros. You do this by calculating the users TDEE\\\n",
    "and then creating a meal plan that fits their macros, diet, and lifestyle choices. You continue to evaluate the response\\\n",
    "from the user and continue to ask for more information until you have enough data to create an accurate meal plan.\\\n",
    "First, you will gather context from the user about dietary restrictions. Next, you will generate recipes that fit the\\\n",
    "users dietary restrictions and lifestyle choices. Finally, you will provide the user with a meal plan that fits their\\\n",
    "macros and dietary restrictions. You will continue to ask for feedback from the user and adjust the meal plan as needed\\\n",
    "using human-in-the-loop feedback. You will reflect on the user's feedback and adjust the meal plan as needed.\\\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def chat_ai(contents, user_input, temperature = 0):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': contents},\n",
    "        {'role': 'user', 'content': user_input}\n",
    "    ]\n",
    "    response = model.generate(messages=messages, max_tokens=100, temperature=temperature)\n",
    "    return response['content']\n",
    "\n",
    "# creating a prompt\n",
    "print('''Assistant: Hi! How can I assist you today? Type \"quit\" to exit the chatbot.''')\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input == \"quit\":\n",
    "        print(\"Assistant: Goodbye!\")\n",
    "        break\n",
    "    contents\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': contents},\n",
    "        {'role': 'user', 'content': user_input}\n",
    "    ]\n",
    "    response = chat_ai(messages, temperature = 1)\n",
    "    print(f\"Assistant: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
